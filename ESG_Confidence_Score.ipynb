{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8492ca-d3d1-4c9b-a4ef-f2c5d986ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets torch scikit-learn pandas numpy nltk\n",
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d40e7-ff2f-4aa2-ae87-3e1e43c94a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"xxxxxxxx\"\n",
    "\n",
    "# List all your Assistants\n",
    "assistants = openai.beta.assistants.list()\n",
    "print(assistants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b5494-dc2b-436f-b50a-076b6cd17f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"xxxxxxx\"\n",
    "\n",
    "# Define your custom assistant ID\n",
    "CUSTOM_ASSISTANT_ID = \"xxxxxxxx\"\n",
    "\n",
    "# Load training data\n",
    "file1 = \"Confidence Score_V1.xlsx\"\n",
    "file2 = \"Confidence Score_V2.xlsx\"\n",
    "df1 = pd.read_excel(file1)\n",
    "df2 = pd.read_excel(file2)\n",
    "\n",
    "# Combine the training data\n",
    "training_data = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "\n",
    "# Print column names to identify the correct text column\n",
    "print(\"Training Data Columns:\", training_data.columns)\n",
    "\n",
    "# Step 1: Combine relevant columns into a single text field for embeddings\n",
    "def combine_text_columns(row):\n",
    "    \"\"\"Merges multiple text fields into one for embeddings.\"\"\"\n",
    "    return f\"Question_Text: {row.get('Question_Text', '')} | Company Response: {row.get('Company_Response', '')} | Analyst Comment: {row.get('Analyst_Comments', '')}\"\n",
    "\n",
    "training_data[\"combined_text\"] = training_data.apply(combine_text_columns, axis=1)\n",
    "\n",
    "# Step 2: Compute embeddings for training data\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    #result = openai.Embedding.create(input=text, model=model)\n",
    "    result = openai.embeddings.create(model=model, input=text)\n",
    "    #return result[\"data\"][0][\"embedding\"]\n",
    "    return result.data[0].embedding\n",
    "\n",
    "# Compute embeddings (replace 'text_column' with 'combined_text')\n",
    "print(\"Precomputing embeddings for training data...\")\n",
    "training_data[\"embedding\"] = training_data[\"combined_text\"].apply(lambda x: get_embedding(str(x)))\n",
    "\n",
    "# Function to find relevant training data for a given question\n",
    "def get_relevant_data(question, training_data, top_n=10):\n",
    "    question_embedding = get_embedding(question)\n",
    "    \n",
    "    # Compute cosine similarity between question and training data embeddings\n",
    "    training_data[\"similarity\"] = training_data[\"embedding\"].apply(\n",
    "        lambda x: cosine_similarity([question_embedding], [x])[0][0]\n",
    "    )\n",
    "    \n",
    "    # Select the top `N` most relevant rows\n",
    "    relevant_data = training_data.sort_values(\"similarity\", ascending=False).head(top_n)\n",
    "    return relevant_data\n",
    "\n",
    "# Load input questions\n",
    "questions_df = pd.read_excel(\"Input_Data_GPT_V1.xlsx\")\n",
    "\n",
    "# Step 3: Create a new thread\n",
    "thread = openai.beta.threads.create()\n",
    "\n",
    "# Step 4: Process each question dynamically\n",
    "responses = []\n",
    "for idx, row in questions_df.iterrows():\n",
    "    question_text = str(row[\"Question_Text\"])\n",
    "    company_response = str(row[\"Company_Response\"])\n",
    "    analyst_comments = str(row[\"Analyst_Comments\"])\n",
    "\n",
    "    user_question = (\n",
    "        f\"Evaluate the confidence score for this ESG-related response.\\n\\n\"\n",
    "        f\"**Question:** {question_text}\\n\"\n",
    "        f\"**Company Response:** {company_response}\\n\"\n",
    "        f\"**Analyst Comments:** {analyst_comments}\\n\\n\"\n",
    "        \"Provide ONLY the following:\\n\"\n",
    "        \"1. Confidence Score (0-100)\\n\"\n",
    "        \"2. Brief Explanation for the score\"\n",
    "    )\n",
    "\n",
    "    # Retrieve relevant training data for the question\n",
    "    print(f\"Retrieving relevant training data for Question {idx + 1}...\")\n",
    "    relevant_data = get_relevant_data(user_question, training_data, top_n=10)\n",
    "    relevant_context = relevant_data[\"combined_text\"].tolist()\n",
    "    relevant_context_text = \"\\n\\n\".join(relevant_context)\n",
    "\n",
    "    # Combine relevant context with the user question\n",
    "    full_context = f\"{relevant_context_text}\\n\\n{user_question}\"\n",
    "\n",
    "    # Send to assistant\n",
    "    openai.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=full_context\n",
    "    )\n",
    "\n",
    "    # Run the assistant\n",
    "    run = openai.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=CUSTOM_ASSISTANT_ID\n",
    "    )\n",
    "\n",
    "    # Poll for response\n",
    "    assistant_response = None\n",
    "    while True:\n",
    "        run_status = openai.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run_status.status == \"completed\":\n",
    "            messages = openai.beta.threads.messages.list(thread_id=thread.id)\n",
    "            for msg in messages.data:\n",
    "                if msg.role == \"assistant\":\n",
    "                    assistant_response = msg.content\n",
    "                    break\n",
    "            if assistant_response:\n",
    "                break\n",
    "        time.sleep(2)  # Polling interval\n",
    "\n",
    "    # Save response\n",
    "    print(f\"Received response for Question {idx + 1}.\")\n",
    "    responses.append(assistant_response)\n",
    "    questions_df.loc[idx, \"Confidence Score & Explanation\"] = assistant_response\n",
    "\n",
    "    # Save progress incrementally\n",
    "    questions_df.to_excel(\"confidence_scores_dynamic.xlsx\", index=False)\n",
    "\n",
    "# Final save\n",
    "questions_df.to_excel(\"confidence_scores_dynamic_final.xlsx\", index=False)\n",
    "print(\"Processing completed. Results saved to 'confidence_scores_dynamic_final.xlsx'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
